# Jupyter Notebook for a Perceptron demo.
# Copyright (C) 2023 Ronny Standtke <ronny.standtke@gmx.net>
# This file is distributed under the same license as the Jupyter Perceptron package.
# Ronny Standtke <ronny.standtke@gmx.net>, 2023
#
msgid ""
msgstr ""
"Project-Id-Version: 0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-22 19:51+0100\n"
"PO-Revision-Date: 2023-10-27 15:55+0200\n"
"Last-Translator: Ronny Standtke <ronny.standtke@gmx.net>\n"
"Language-Team: DE <DE@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../Perceptron.py:52
msgid "<h1>Theory</h1>"
msgstr "<h1>Theorie</h1>"

#: ../Perceptron.py:53
msgid "<h2>Why machine learning?</h2>"
msgstr "<h2>Warum maschinelles Lernen?</h2>"

#: ../Perceptron.py:54
msgid ""
"\n"
"            <p>In the past, we typically used a programming language such as "
"C,\n"
"            Java or Python to solve problems with computers, using explicit\n"
"            commands to create the data structures, algorithms, functions "
"and\n"
"            ultimately executable programs required for the solution. This\n"
"            approach can be used to create excellent solutions in many "
"areas.\n"
"            However, in complex situations, such as large amounts of data "
"or\n"
"            dynamically changing environments, we reach the limits of\n"
"            conventional programming, e.g. in speech recognition, "
"autonomous\n"
"            driving or medical diagnostics.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Um Aufgaben mit Computern zu lösen, haben wir in der "
"Vergangenheit typischerweise eine Programmiersprache wie z.B. C, Java oder "
"Python verwendet, um mit expliziten Befehlen die zur Lösung notwendigen "
"Datenstrukturen, Algorithmen, Funktionen und schlussendlich ausführbaren "
"Programme zu erstellen. Mit dieser Herangehensweise lassen sich in vielen "
"Bereichen hervorragende Lösungen erstellen. Dennoch stoßen wir in komplexen "
"Situationen, wie bei großen Datenmengen oder sich dynamisch ändernden "
"Umgebungen, an die Grenzen herkömmlicher Programmierung, z.B. bei "
"Spracherkennung, autonomem Fahren oder medizinischen Diagnosen.</p>\n"
"            "

#: ../Perceptron.py:65
msgid ""
"\n"
"            <p>In order to efficiently create solutions for these complex\n"
"            applications, the field of machine learning has established "
"itself\n"
"            as a supplement to traditional programming. As is so often the\n"
"            case, the model for machine learning is taken from nature: the\n"
"            brain with its network of neurons. In order to understand the\n"
"            mathematical model based on this, let's first take a look at how "
"a\n"
"            biological neuron works:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Um Lösungen für diese komplexen Anwendungsfälle effizient "
"erstellen zu können, hat sich als Ergänzung zur klassischen Programmierung "
"das Gebiet des maschinellen Lernens etabliert. Als Vorlage für das "
"maschinelle Lernen dient, wie so häufig, das entsprechende Vorbild aus der "
"Natur: das Gehirn mit seinem Verbund aus Nervenzellen. Um das darauf "
"aufbauende mathematische Modell zu verstehen, schauen wir uns also zunächst "
"die Funktionsweise einer biologischen Nervenzelle an:</p>\n"
"            "

#: ../Perceptron.py:74
msgid "<h2>Biological neuron</h2>"
msgstr "<h2>Biologische Nervenzelle</h2>"

#: ../Perceptron.py:79
msgid "neuron_en.png"
msgstr "neuron_de.png"

#: ../Perceptron.py:84
msgid ""
"\n"
"            <p>In simple terms, biological neurons function by receiving "
"and\n"
"            transmitting electrical impulses. Reception takes place via the\n"
"            dentrites. The potentials of the electrical impulses received "
"are\n"
"            summed up in the cell body (soma). As soon as this sum exceeds "
"a\n"
"            certain threshold value, the action potential, the electrical\n"
"            impulse is transmitted on the axon. This works according to the\n"
"            all-or-nothing principle: as long as the action potential is "
"not\n"
"            reached, no impulse is transmitted at all; as soon as it is\n"
"            reached, the impulse is transmitted. The closer a dendrite is "
"to\n"
"            the axon, the stronger the influence of its incoming impulse on "
"the\n"
"            action potential in the cell body. Its proximity to the axon\n"
"            therefore influences the \"weighting\" of a dendrite. "
"Transmitted\n"
"            impulses are transferred to other cells (e.g. other neurons, "
"gland\n"
"            or muscle cells) at the axon terminals.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Biologische Nervenzellen funktionieren vereinfacht gesagt "
"über den Empfang und die Weitergabe von elektrischen Impulsen. Der Empfang "
"erfolgt über die Dentriten. Die Potenziale der empfangenen elektrischen "
"Impulse werden im Zellkörper (Soma) aufsummiert. Sobald diese Summe einen "
"bestimmten Schwellenwert, das Aktionspotenzial, überschreitet, wird der "
"elektrische Impuls auf dem Axon weitergegeben. Das funktioniert nach dem "
"Alles-oder-nichts-Prinzip: solange das Aktionspotenzial nicht erreicht ist, "
"wird gar kein Impuls weitergegeben, sobald es erreicht ist, wird der Impuls "
"weitergeleitet. Je näher sich ein Dendrit sich am Axon befindet, desto "
"stärker ist der Einfluss seines eingehenden Impulses auf das "
"Aktionspotenzial im Zellkörper. Seine Nähe zum Axon beeinflusst also die "
"\"Gewichtung\" eines Dendrits. Weitergeleitete Impulse werden an den "
"Axonterminalen auf andere Zellen (z.B. andere Nervenzellen, Drüsen- oder "
"Muskelzellen) übertragen.</p>\n"
"            "

#: ../Perceptron.py:100
msgid ""
"\n"
"            <p>The almost 100 billion neurons in our human brain each have\n"
"            around 10,000 dendrites, enabling us to perform our outstanding\n"
"            learning and thinking abilities.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Die knapp 100 Milliarden Nervenzellen in unserem menschlichen "
"Gehirn verfügen jeweils über ungefähr 10.000 Dendriten und ermöglichen uns "
"so unsere herausragenden Lern- und Denkfähigkeiten.</p>\n"
"            "

#: ../Perceptron.py:105
msgid ""
"\n"
"            <p>The simplified model of a biological neuron described above "
"can\n"
"            now be converted into a mathematical model:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Das beschriebene vereinfachte Modell einer biologischen "
"Nervenzelle kann nun in ein mathematisches Modell überführt werden:</p>\n"
"            "

#: ../Perceptron.py:109
msgid "<h2>Artificial neuron</h2>"
msgstr "<h2>Künstliche Nervenzelle</h2>"

#: ../Perceptron.py:112
msgid "artificial_neuron_en.png"
msgstr "artificial_neuron_de.png"

#: ../Perceptron.py:117
msgid ""
"\n"
"            <p>\n"
"            <ul>\n"
"                <li>\n"
"                    the dentrites become the inputs x<sub>1</sub> to\n"
"                    x<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    the proximity of the dentrites to the axon is indicated "
"by\n"
"                    the respective weights w<sub>1</sub> to w<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    the summation of the received electrical impulses in "
"the\n"
"                    cell body is mapped in the transfer function\n"
"                </li>\n"
"                <li>\n"
"                    the action potential is stored in the threshold value\n"
"                    &theta;\n"
"                </li>\n"
"                <li>\n"
"                    the all-or-nothing principle is represented by the\n"
"                    activation function\n"
"                </li>\n"
"            </ul>\n"
"            </p>\n"
"            "
msgstr ""
"\n"
"            <p>\n"
"            <ul>\n"
"                <li>\n"
"                    die Dentriten werden zu den Eingaben x<sub>1</sub> bis\n"
"                    x<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    die Nähe der Dentriten zum Axon wird durch "
"die                     jeweiligen Gewichtungen w<sub>1</sub> to w<sub>n</"
"sub>                     angegeben                </li>\n"
"                <li>\n"
"                    die Aufsummierung der empfangenen elektrischen Impulse "
"im                     Zellkörper wird in der Übertragungsfunktion "
"abgebildet                </li>\n"
"                <li>\n"
"                    das Aktionspotenzial wird im Schwellenwert &theta; "
"hinterlegt                 </li>\n"
"                <li>\n"
"                    das Alles-oder-nichts-Prinzip wird durch "
"die                     Aktivierungsfunktion abgebildet                </"
"li>\n"
"            </ul>\n"
"            </p>\n"
"            "

#: ../Perceptron.py:143
msgid ""
"\n"
"            <p>But how does an artificial neuron \"learn\"? Let's try it "
"with a\n"
"            very simple example...</p>\n"
"            "
msgstr ""
"\n"
"            <p>Aber wie \"lernt\" jetzt so eine künstliche Nervenzelle? "
"Versuchen wir es an einem ganz einfachen Beispiel...</p>\n"
"            "

#: ../Perceptron.py:147
msgid "<h2>Example</h2>"
msgstr "<h2>Beispiel</h2>"

#: ../Perceptron.py:148
msgid ""
"\n"
"            <p>In our example, there should be exactly two inputs, each of "
"which\n"
"            can only accept truth values (i.e. \"true\" or \"false\"). The "
"two\n"
"            inputs are:\n"
"            <ul>\n"
"                <li>It is weekend.</li>\n"
"                <li>Parents come to visit.</li>\n"
"            </ul>\n"
"            We want to use these two inputs to determine whether it is a "
"good\n"
"            day:</p>\n"
"            "
msgstr ""
"\n"
"            <p>In unserem Beispiel soll es genau zwei Eingaben geben, die "
"jeweils nur Wahrheitswerte (also \"wahr\" oder \"falsch\") annehmen können. "
"Die beiden Eingaben sind:            <ul>\n"
"                <li>Es ist Wochenende.</li>\n"
"                <li>Die Eltern kommen zu Besuch.</li>\n"
"            </ul>\n"
"            Mit diesen beiden Eingaben wollen wir bestimmen, ob ein guter "
"Tag ist:</p>\n"
"            "

#: ../Perceptron.py:161
msgid "good_day_empty_en.png"
msgstr "good_day_empty_de.png"

#: ../Perceptron.py:166
msgid ""
"\n"
"            <p>As you can easily imagine, the answer to this question is "
"very\n"
"            individual. Let's assume we are looking at the situation for a\n"
"            person for whom it is always a good day when it is weekend or\n"
"            their parents are visiting, or both:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Wie man sich leicht denken kann, ist die Antwort auf diese "
"Frage sehr individuell. Nehmen wir an, wir betrachten die Situation für "
"einen Menschen, für den immer dann ein guter Tag ist, wenn Wochenende ist "
"oder die Eltern zu Besuch sind, oder beides zutrifft:</p>\n"
"            "

#: ../Perceptron.py:174
msgid "good_day_example_en.png"
msgstr "good_day_example_de.png"

#: ../Perceptron.py:179
msgid ""
"\n"
"            <p>If you have ever programmed before, you will most likely\n"
"            immediately see that we are dealing with an OR operation of the "
"two\n"
"            inputs. But for once, we do <em>NOT</em> want to solve this "
"task\n"
"            with explicit commands, but rather teach an artificial neuron "
"to\n"
"            always generate the desired output for all possible variations "
"of\n"
"            the inputs.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Wenn Sie schon einmal programmiert haben, werden Sie "
"höchstwahrscheinlich sofort sehen, dass wir es hier mit einer ODER-"
"Verknüpfung der beiden Eingänge zu tun haben. Aber wir wollen diese Aufgabe "
"ausnahmsweise einmal <em>NICHT</em> mit expliziten Befehlen lösen, sondern "
"einer künstlichen Nervenzelle beibringen, bei allen möglichen Variationen "
"der Eingaben immer die gewünschte Ausgabe zu erzeugen.</p>\n"
"            "

#: ../Perceptron.py:187
msgid ""
"\n"
"            <p>To do this, we actually just have to set all the\n"
"            <span style=\"color:red\">weights</span> and the\n"
"            <span style=\"color:red\">threshold value</span> in our "
"artificial\n"
"            neuron appropriately:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Dazu müssen wir eigentlich nur alle <span style=\"color:"
"red\">Gewichtungen</span> und den <span style=\"color:red\">Schwellenwert</"
"span> in unserer künstlichen Nervenzelle passend einstellen:</p>\n"
"            "

#: ../Perceptron.py:195
msgid "simple_neuron_en.png"
msgstr "simple_neuron_de.png"

#: ../Perceptron.py:200
msgid ""
"\n"
"            <p>But how do you find the right values in a targeted and "
"efficient\n"
"            way? Or to put it another way: How does an artificial neuron "
"\"learn\"?</p>\n"
"            "
msgstr ""
"\n"
"            <p>Aber wie findet man denn zielgerichtet und effizient die "
"passenden Werte? Oder anders formuliert: Wie \"lernt\" ein künstliches "
"Neuron?</p>\n"
"            "

#: ../Perceptron.py:204
msgid ""
"\n"
"            <p>The learning process for an artificial neuron could look "
"like\n"
"            this, for example:\n"
"            <ol>\n"
"                <li>\n"
"                    Choose random values for the weights and the threshold.\n"
"                </li>\n"
"                <li>Determine and check the result for selected inputs.</"
"li>\n"
"                <li>\n"
"                    If the result is not as expected, adjust the weights "
"and\n"
"                    threshold in <span style=\"color:red\">a reasonable\n"
"                    direction</span> and <span style=\"color:"
"red\">dimension\n"
"                    </span>. Jump back to point 2.\n"
"                </li>\n"
"                <li>Done, training successful.</li>\n"
"            </ol>\n"
"            </p>\n"
"            "
msgstr ""
"\n"
"            <p>Der Lernprozess bei einem künstlichen Neuron könnte zum "
"Beispiel so aussehen:             <ol>\n"
"                <li>\n"
"                    Wähle zufällige Werte für die Gewichtungen und den "
"Schwellenwert.\n"
"                </li>\n"
"                <li>Ermittle und überprüfe das Ergebnis für ausgewählte "
"Eingaben.</li>\n"
"                <li>\n"
"                    Falls das Ergebnis nicht den Erwartungen entspricht, "
"passe die Gewichtungen und den Schwellenwert in <span style=\"color:"
"red\">eine sinnvolle Richtung</span> und <span style=\"color:red\">in "
"geeigneter Dimension</span> an. Springe zurück zu Punkt 2.\n"
"                </li>\n"
"                <li>Fertig, Training erfolgreich.</li>\n"
"            </ol>\n"
"            </p>\n"
"            "

#: ../Perceptron.py:224
msgid "learning_direction_and_dimension_en.png"
msgstr "learning_direction_and_dimension_de.png"

#: ../Perceptron.py:229
msgid ""
"\n"
"            <p>So that we do not always have to distinguish between the\n"
"            weightings and the threshold value, we now simplify our model "
"once\n"
"            again from a mathematical point of view: The threshold value\n"
"            becomes the special weighting x<sub>0</sub>, whose input is "
"always\n"
"            1 (also referred to as \"bias\" in the specialist literature):</"
"p>\n"
"            "
msgstr ""
"\n"
"            <p>Damit wir nicht immer zwischen den Gewichtungen und dem "
"Schwellenwert unterscheiden müssen, vereinfachen wir unser Modell nun noch "
"einmal aus mathematischer Sicht: Der Schwellenwert wird zur speziellen "
"Gewichtung x<sub>0</sub>, dessen Eingabe immer 1 ist (in der Fachliteratur "
"auch als \"Bias\" bezeichnet):</p>\n"
"            "

#: ../Perceptron.py:243
msgid ""
"\n"
"            <p>Looking at the last formula, it becomes obvious that we can "
"now\n"
"            calculate with vectors:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Beim Betrachten der letzten Formel wird offensichtlich, dass "
"wir nun mit Vektoren rechnen können:</p>\n"
"            "

#: ../Perceptron.py:254
msgid ""
"\n"
"            <p>And now you can perhaps already guess why powerful graphics\n"
"            cards are so popular for training and using AI models: "
"Calculations\n"
"            with vectors, scalar products (and later also calculations with\n"
"            matrices) are precisely the use cases in which graphics cards "
"are\n"
"            clearly superior to a normal processor, as they are built and\n"
"            optimized precisely for such calculations.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Und jetzt ahnt man vielleicht schon, warum leistungsfähige "
"Grafikkarten für das Training und die Anwendung von KI-Modellen so beliebt "
"sind: Das Rechnen mit Vektoren, Skalarprodukten (und später auch noch "
"Berechnungen mit Matrizen) sind genau die Anwendungsfälle, in denen "
"Grafikkarten einem normalen Prozessor deutlich überlegen sind, da sie genau "
"für solche Berechnungen gebaut und optimiert werden.</p>\n"
"            "

#: ../Perceptron.py:273
msgid ""
"\n"
"            <h1>Training</h1>\n"
"            In this area the perceptron can be trained:\n"
"            <ol>\n"
"                <li>\n"
"                    Select the checkboxes for the combinations you consider "
"a\n"
"                    nice day in the rightmost column.\n"
"                </li>\n"
"                <li>Press the start button to start the learning process.</"
"li>\n"
"                <li>\n"
"                    Press the \"Finalize Epoch\" button to continue "
"learning\n"
"                    until the current epoch is finished.\n"
"                </li>\n"
"                <li>\n"
"                    Press the \"Reset\" button to reset the learning "
"process.\n"
"                </li>\n"
"            </ol>\n"
"            "
msgstr ""
"\n"
"            <h1>Training</h1>\n"
"            In diesem Bereich kann das Perzeptron trainiert werden:\n"
"            <ol>\n"
"                <li>\n"
"                    Wählen Sie in der rechten Spalte die Checkboxen für die "
"Kombinationen, die Sie für schöne Tage halten.                 </li>\n"
"                <li>Drücken Sie den Startknopf, um den Lernprozess zu "
"starten.</li>\n"
"                <li>\n"
"                    Drücken Sie den Knopf \"Epoche abschließen\", um so "
"lange zu lernen, bis die aktuelle Epoche abgeschlossen wurde.                "
"</li>\n"
"                <li>\n"
"                    Drücken Sie den Knopf \"Zurücksetzen\", um den "
"Lernprozess zurückzusetzen.                </li>\n"
"            </ol>\n"
"            "

#: ../Perceptron.py:306
msgid "Weekend"
msgstr "Wochenende"

#: ../Perceptron.py:326
msgid "Visiting Parents"
msgstr "Eltern zu Besuch"

#: ../Perceptron.py:346
msgid "Nice Day?"
msgstr "Schöner Tag?"

#: ../Perceptron.py:363
msgid "Learning Rate α:"
msgstr "Lernrate α"

#: ../Perceptron.py:371
msgid "Finalize Epoch"
msgstr "Epoche abschließen"

#: ../Perceptron.py:375
msgid "Reset"
msgstr "Zurücksetzen"

#: ../Perceptron.py:389
msgid ""
"\n"
"            <h1>Inference</h1>\n"
"            In this area the perceptron can be used:\n"
"            <ol>\n"
"                <li>\n"
"                    Change the selection of the two input checkboxes on the\n"
"                    left hand side.\n"
"                </li>\n"
"                <li>Watch the result on the righthand side.</li>\n"
"            </ol>\n"
"            "
msgstr ""
"\n"
"            <h1>Inferenz</h1>\n"
"            In diesem Bereich kann das Perzeptron benutzt werden:\n"
"            <ol>\n"
"                <li>\n"
"                    Ändern Sie die Auswahl der beiden Eingabe-Checkboxen auf "
"der linken Seite.                 </li>\n"
"                <li>Beobachten Sie das Ergebnis auf der rechten Seite.</li>\n"
"            </ol>\n"
"            "

#: ../Perceptron.py:446
msgid "Start (set random weights))"
msgstr "Start (zufällige Gewichtungen setzen)"

#: ../Perceptron.py:451
msgid "Continue (get random input)"
msgstr "Weiter (zufälligen Input holen)"

#: ../Perceptron.py:453
msgid "Continue (calculate result)"
msgstr "Weiter (Ausgabe berechnen)"

#: ../Perceptron.py:455
msgid "Continue (adopt weights)"
msgstr "Weiter (Gewichtungen anpassen)"

#: ../Perceptron.py:502 ../Perceptron.py:650
msgid "Epoch: "
msgstr "Epoche: "

#: ../temp.py:52
msgid ""
"\n"
"                <h1>Startup failed</h1>\n"
"                The startup of this notebook has failed. A known cause for "
"this\n"
"                error is starting the notebook in Firefox in private mode.\n"
"                Please try again in a new Firefox window in normal mode. "
"More\n"
"                background information about this problem can be found "
"here:\n"
"                <br>\n"
"                <a href=\"https://jupyterlite.readthedocs.io/en/latest/howto/"
"configure/advanced/service-worker.html\" target=\"_blank\">\n"
"                https://jupyterlite.readthedocs.io/en/latest/howto/configure/"
"advanced/service-worker.html</a>\n"
"                "
msgstr ""
"\n"
"                <h1>Start fehlgeschlagen</h1>\n"
"                Der Start dieses Notebooks ist fehlgeschlagen. Eine "
"bekannte                Ursache für diesen Fehler ist der Start des "
"Notebooks in                Firefox im privaten Modus. Bitte versuchen Sie "
"es noch einmal                in einem neuen Firefox-Fenster im normalen "
"Modus. Weitere                Hintergrundinformationen zu diesem Problem "
"sind hier zu                finden:                <br>\n"
"                <a href=\"https://jupyterlite.readthedocs.io/en/latest/howto/"
"configure/advanced/service-worker.html\" target=\"_blank\">\n"
"                https://jupyterlite.readthedocs.io/en/latest/howto/configure/"
"advanced/service-worker.html</a>\n"
"                "
