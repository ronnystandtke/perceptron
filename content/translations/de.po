# Jupyter Notebook for a Perceptron demo.
# Copyright (C) 2023 Ronny Standtke <ronny.standtke@gmx.net>
# This file is distributed under the same license as the Jupyter Perceptron package.
# Ronny Standtke <ronny.standtke@gmx.net>, 2023
#
msgid ""
msgstr ""
"Project-Id-Version: 0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-30 20:44+0100\n"
"PO-Revision-Date: 2023-10-27 15:55+0200\n"
"Last-Translator: Ronny Standtke <ronny.standtke@gmx.net>\n"
"Language-Team: DE <DE@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../Perceptron.py:52
msgid "<h1>Theory</h1>"
msgstr "<h1>Theorie</h1>"

#: ../Perceptron.py:53
msgid "<h2>Why machine learning?</h2>"
msgstr "<h2>Warum maschinelles Lernen?</h2>"

#: ../Perceptron.py:54
msgid ""
"\n"
"            <p>In the past, we typically used a programming language such as "
"C,\n"
"            Java or Python to solve problems with computers, using explicit\n"
"            commands to create the data structures, algorithms, functions "
"and\n"
"            ultimately executable programs required for the solution. This\n"
"            approach can be used to create excellent solutions in many "
"areas.\n"
"            However, in complex situations, such as large amounts of data "
"or\n"
"            dynamically changing environments, we reach the limits of\n"
"            conventional programming, e.g. in speech recognition, "
"autonomous\n"
"            driving or medical diagnostics.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Um Aufgaben mit Computern zu lösen, haben wir in der "
"Vergangenheit typischerweise eine Programmiersprache wie z.B. C, Java oder "
"Python verwendet, um mit expliziten Befehlen die zur Lösung notwendigen "
"Datenstrukturen, Algorithmen, Funktionen und schlussendlich ausführbaren "
"Programme zu erstellen. Mit dieser Herangehensweise lassen sich in vielen "
"Bereichen hervorragende Lösungen erstellen. Dennoch stoßen wir in komplexen "
"Situationen, wie bei großen Datenmengen oder sich dynamisch ändernden "
"Umgebungen, an die Grenzen herkömmlicher Programmierung, z.B. bei "
"Spracherkennung, autonomem Fahren oder medizinischen Diagnosen.</p>\n"
"            "

#: ../Perceptron.py:65
msgid ""
"\n"
"            <p>In order to efficiently create solutions for these complex\n"
"            applications, the field of machine learning has established "
"itself\n"
"            as a supplement to traditional programming. As is so often the\n"
"            case, the model for machine learning is taken from nature: the\n"
"            brain with its network of neurons. In order to understand the\n"
"            mathematical model based on this, let's first take a look at how "
"a\n"
"            biological neuron works:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Um Lösungen für diese komplexen Anwendungsfälle effizient "
"erstellen zu können, hat sich als Ergänzung zur klassischen Programmierung "
"das Gebiet des maschinellen Lernens etabliert. Als Vorlage für das "
"maschinelle Lernen dient, wie so häufig, das entsprechende Vorbild aus der "
"Natur: das Gehirn mit seinem Verbund aus Nervenzellen. Um das darauf "
"aufbauende mathematische Modell zu verstehen, schauen wir uns also zunächst "
"die Funktionsweise einer biologischen Nervenzelle an:</p>\n"
"            "

#: ../Perceptron.py:74
msgid "<h2>Biological neuron</h2>"
msgstr "<h2>Biologische Nervenzelle</h2>"

#: ../Perceptron.py:79
msgid "neuron_en.png"
msgstr "neuron_de.png"

#: ../Perceptron.py:84
msgid ""
"\n"
"            <p>In simple terms, biological neurons function by receiving "
"and\n"
"            transmitting electrical impulses. Reception takes place via the\n"
"            dendrites. The potentials of the electrical impulses received "
"are\n"
"            summed up in the cell body (soma). As soon as this sum exceeds "
"a\n"
"            certain threshold value, the action potential, the electrical\n"
"            impulse is transmitted on the axon. This works according to the\n"
"            all-or-nothing principle: as long as the action potential is "
"not\n"
"            reached, no impulse is transmitted at all; as soon as it is\n"
"            reached, the impulse is transmitted. The closer a dendrite is "
"to\n"
"            the axon, the stronger the influence of its incoming impulse on "
"the\n"
"            action potential in the cell body. Its proximity to the axon\n"
"            therefore influences the \"weighting\" of a dendrite. "
"Transmitted\n"
"            impulses are transferred to other cells (e.g. other neurons, "
"gland\n"
"            or muscle cells) at the axon terminals.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Biologische Nervenzellen funktionieren vereinfacht gesagt "
"über den Empfang und die Weitergabe von elektrischen Impulsen. Der Empfang "
"erfolgt über die Dendriten. Die Potenziale der empfangenen elektrischen "
"Impulse werden im Zellkörper (Soma) aufsummiert. Sobald diese Summe einen "
"bestimmten Schwellenwert, das Aktionspotenzial, überschreitet, wird der "
"elektrische Impuls auf dem Axon weitergegeben. Das funktioniert nach dem "
"Alles-oder-nichts-Prinzip: solange das Aktionspotenzial nicht erreicht ist, "
"wird gar kein Impuls weitergegeben, sobald es erreicht ist, wird der Impuls "
"weitergeleitet. Je näher sich ein Dendrit am Axon befindet, desto stärker "
"ist der Einfluss seines eingehenden Impulses auf das Aktionspotenzial im "
"Zellkörper. Seine Nähe zum Axon beeinflusst also die \"Gewichtung\" eines "
"Dendrits. Weitergeleitete Impulse werden an den Axonterminalen auf andere "
"Zellen (z.B. andere Nervenzellen, Drüsen- oder Muskelzellen) übertragen.</"
"p>\n"
"            "

#: ../Perceptron.py:100
msgid ""
"\n"
"            <p>The almost 100 billion neurons in our human brain each have\n"
"            around 10,000 dendrites, enabling us to perform our outstanding\n"
"            learning and thinking abilities.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Die knapp 100 Milliarden Nervenzellen in unserem menschlichen "
"Gehirn verfügen jeweils über ungefähr 10.000 Dendriten und ermöglichen uns "
"so unsere herausragenden Lern- und Denkfähigkeiten.</p>\n"
"            "

#: ../Perceptron.py:105
msgid ""
"\n"
"            <p>The simplified model of a biological neuron described above "
"can\n"
"            now be converted into a mathematical model:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Das beschriebene vereinfachte Modell einer biologischen "
"Nervenzelle kann nun in ein mathematisches Modell überführt werden:</p>\n"
"            "

#: ../Perceptron.py:109
msgid "<h2>Artificial neuron</h2>"
msgstr "<h2>Künstliche Nervenzelle</h2>"

#: ../Perceptron.py:112
msgid "artificial_neuron_en.png"
msgstr "artificial_neuron_de.png"

#: ../Perceptron.py:117
msgid ""
"\n"
"            <p>\n"
"            <ul>\n"
"                <li>\n"
"                    the dendrites become the inputs i<sub>1</sub> to\n"
"                    i<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    the proximity of the dendrites to the axon is indicated "
"by\n"
"                    the respective weights w<sub>1</sub> to w<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    the summation of the received electrical impulses in "
"the\n"
"                    cell body is mapped in the transfer function\n"
"                </li>\n"
"                <li>\n"
"                    the action potential is stored in the threshold value\n"
"                    &theta;\n"
"                </li>\n"
"                <li>\n"
"                    the all-or-nothing principle is represented by the\n"
"                    activation function\n"
"                </li>\n"
"            </ul>\n"
"            </p>\n"
"            "
msgstr ""
"\n"
"            <p>\n"
"            <ul>\n"
"                <li>\n"
"                    die Dendriten werden zu den Eingaben i<sub>1</sub> bis\n"
"                    i<sub>n</sub>\n"
"                </li>\n"
"                <li>\n"
"                    die Nähe der Dendriten zum Axon wird durch "
"die                     jeweiligen Gewichtungen w<sub>1</sub> bis w<sub>n</"
"sub>                     angegeben                </li>\n"
"                <li>\n"
"                    die Aufsummierung der empfangenen elektrischen Impulse "
"im                     Zellkörper wird in der Übertragungsfunktion "
"abgebildet                </li>\n"
"                <li>\n"
"                    das Aktionspotenzial wird im Schwellenwert &theta; "
"hinterlegt                 </li>\n"
"                <li>\n"
"                    das Alles-oder-nichts-Prinzip wird durch "
"die                     Aktivierungsfunktion abgebildet                </"
"li>\n"
"            </ul>\n"
"            </p>\n"
"            "

#: ../Perceptron.py:143
msgid ""
"\n"
"            <p>But how does an artificial neuron \"learn\"? Let's try it "
"with a\n"
"            very simple example...</p>\n"
"            "
msgstr ""
"\n"
"            <p>Aber wie \"lernt\" jetzt so eine künstliche Nervenzelle? "
"Versuchen wir es an einem ganz einfachen Beispiel...</p>\n"
"            "

#: ../Perceptron.py:147
msgid "<h2>Example</h2>"
msgstr "<h2>Beispiel</h2>"

#: ../Perceptron.py:148
msgid ""
"\n"
"            <p>In our example, there should be exactly two inputs, each of "
"which\n"
"            can only accept truth values (i.e. \"true\" or \"false\"). The "
"two\n"
"            inputs are:\n"
"            <ul>\n"
"                <li>It is weekend.</li>\n"
"                <li>Parents come to visit.</li>\n"
"            </ul>\n"
"            We want to use these two inputs to determine whether it is a "
"good\n"
"            day:</p>\n"
"            "
msgstr ""
"\n"
"            <p>In unserem Beispiel soll es genau zwei Eingaben geben, die "
"jeweils nur Wahrheitswerte (also \"wahr\" oder \"falsch\") annehmen können. "
"Die beiden Eingaben sind:            <ul>\n"
"                <li>Es ist Wochenende.</li>\n"
"                <li>Die Eltern kommen zu Besuch.</li>\n"
"            </ul>\n"
"            Mit diesen beiden Eingaben wollen wir bestimmen, ob ein guter "
"Tag ist:</p>\n"
"            "

#: ../Perceptron.py:161
msgid "good_day_empty_en.png"
msgstr "good_day_empty_de.png"

#: ../Perceptron.py:166
msgid ""
"\n"
"            <p>As you can easily imagine, the answer to this question is "
"very\n"
"            individual. Let's assume we are looking at the situation for a\n"
"            person for whom it is always a good day when it is weekend or\n"
"            their parents are visiting, or both:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Wie man sich leicht denken kann, ist die Antwort auf diese "
"Frage sehr individuell. Nehmen wir an, wir betrachten die Situation für "
"einen Menschen, für den immer dann ein guter Tag ist, wenn Wochenende ist "
"oder die Eltern zu Besuch kommen, oder beides zutrifft:</p>\n"
"            "

#: ../Perceptron.py:174
msgid "good_day_example_en.png"
msgstr "good_day_example_de.png"

#: ../Perceptron.py:179
msgid ""
"\n"
"            <p>If you have ever programmed before, you will most likely\n"
"            immediately see that we are dealing with an OR operation of the "
"two\n"
"            inputs. But for once, we do <em>NOT</em> want to solve this "
"task\n"
"            with explicit commands, but rather teach an artificial neuron "
"to\n"
"            always generate the desired output for all possible variations "
"of\n"
"            the inputs.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Wenn Sie schon einmal programmiert haben, werden Sie "
"höchstwahrscheinlich sofort sehen, dass wir es hier mit einer ODER-"
"Verknüpfung der beiden Eingaben zu tun haben. Aber wir wollen diese Aufgabe "
"ausnahmsweise einmal <em>NICHT</em> mit expliziten Befehlen lösen, sondern "
"einer künstlichen Nervenzelle beibringen, bei allen möglichen Variationen "
"der Eingaben immer die gewünschte Ausgabe zu erzeugen.</p>\n"
"            "

#: ../Perceptron.py:187
msgid "<h2>Machine learning</h2>"
msgstr "<h2>Maschinelles Lernen</h2>"

#: ../Perceptron.py:188
msgid ""
"\n"
"            <p>To do this, we must first assign numerical values to the "
"truth\n"
"            values of the two inputs. Usually, \"true\" is assigned 1 and "
"\"false\"\n"
"            0. Example: If it is weekend, the input i<sub>1</sub> is "
"assigned\n"
"            the value 1 and if the parents are not coming to visit, the "
"input\n"
"            i<sub>2</sub> is assigned the value 0.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Dazu müssen wir den Wahrheitswerten der beiden Eingänge "
"zunächst numerische Werte zuordnen. Normalerweise wird \"wahr\" mit 1 und "
"\"falsch\" mit 0 belegt. Beispiel: Wenn es Wochenende ist, erhält der "
"Eingang i<sub>1</sub> den Wert 1 und wenn die Eltern nicht zu Besuch kommen, "
"erhält der Eingang i<sub>2</sub> den Wert 0.</p>\n"
"            "

#: ../Perceptron.py:195
msgid ""
"\n"
"            <p>Then we only have to set the\n"
"            <span style=\"color:red\">weights</span> and the\n"
"            <span style=\"color:red\">threshold value</span> in our "
"artificial\n"
"            neuron accordingly:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Dann müssen wir eigentlich nur noch alle <span style=\"color:"
"red\">Gewichtungen</span> und den <span style=\"color:red\">Schwellenwert</"
"span> in unserer künstlichen Nervenzelle passend einstellen:</p>\n"
"            "

#: ../Perceptron.py:203
msgid "simple_neuron_en.png"
msgstr "simple_neuron_de.png"

#: ../Perceptron.py:208
msgid ""
"\n"
"            <p>But how do you find the right values in a targeted and "
"efficient\n"
"            way? Or to put it another way: How does an artificial neuron "
"\"learn\"?</p>\n"
"            "
msgstr ""
"\n"
"            <p>Aber wie findet man denn zielgerichtet und effizient die "
"passenden Werte? Oder anders formuliert: Wie \"lernt\" eine künstliche "
"Nervenzelle?</p>\n"
"            "

#: ../Perceptron.py:212
msgid ""
"\n"
"            <p>The learning process for an artificial neuron could look "
"like\n"
"            this, for example:\n"
"            <ol>\n"
"                <li>\n"
"                    Choose random values for the weights and the threshold.\n"
"                </li>\n"
"                <li>Determine and check the result for selected inputs.</"
"li>\n"
"                <li>\n"
"                    If the result is not as expected, adjust the weights "
"and\n"
"                    threshold in <span style=\"color:red\">a reasonable\n"
"                    direction</span> and <span style=\"color:"
"red\">dimension\n"
"                    </span>. Jump back to point 2.\n"
"                </li>\n"
"                <li>Done, training successful.</li>\n"
"            </ol>\n"
"            </p>\n"
"            "
msgstr ""
"\n"
"            <p>Der Lernprozess bei einer künstlichen Nervenzelle könnte zum "
"Beispiel so aussehen:             <ol>\n"
"                <li>\n"
"                    Wähle zufällige Werte für die Gewichtungen und den "
"Schwellenwert.\n"
"                </li>\n"
"                <li>Ermittle und überprüfe das Ergebnis für ausgewählte "
"Eingaben.</li>\n"
"                <li>\n"
"                    Falls das Ergebnis nicht den Erwartungen entspricht, "
"passe die Gewichtungen und den Schwellenwert in <span style=\"color:"
"red\">eine sinnvolle Richtung</span> und <span style=\"color:red\">in "
"geeigneter Dimension</span> an. Springe zurück zu Punkt 2.\n"
"                </li>\n"
"                <li>Fertig, Training erfolgreich.</li>\n"
"            </ol>\n"
"            </p>\n"
"            "

#: ../Perceptron.py:232
msgid "learning_direction_and_dimension_en.png"
msgstr "learning_direction_and_dimension_de.png"

#: ../Perceptron.py:237
msgid ""
"\n"
"            <p>So that we do not always have to distinguish between the\n"
"            weights and the threshold value, we now simplify our model once\n"
"            again from a mathematical point of view: The threshold value\n"
"            becomes the special weight w<sub>0</sub>, whose input is always\n"
"            1 (also referred to as \"bias\" in the specialist literature):</"
"p>\n"
"            "
msgstr ""
"\n"
"            <p>Damit wir nicht immer zwischen den Gewichtungen und dem "
"Schwellenwert unterscheiden müssen, vereinfachen wir unser Modell nun noch "
"einmal aus mathematischer Sicht: Der Schwellenwert wird zur speziellen "
"Gewichtung w<sub>0</sub>, dessen Eingabe immer 1 ist (in der Fachliteratur "
"auch als \"Bias\" bezeichnet):</p>\n"
"            "

#: ../Perceptron.py:251
msgid ""
"\n"
"            <p>Looking at the last formula, it becomes obvious that we can "
"now\n"
"            calculate with vectors:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Beim Betrachten der letzten Formel wird offensichtlich, dass "
"wir nun mit Vektoren rechnen können:</p>\n"
"            "

#: ../Perceptron.py:262
msgid ""
"\n"
"            <p>And now you can perhaps already guess why powerful graphics\n"
"            cards are so popular for training and using AI models: "
"Calculations\n"
"            with vectors, scalar products (and later also calculations with\n"
"            matrices) are precisely the use cases in which graphics cards "
"are\n"
"            clearly superior to a normal processor, as they are built and\n"
"            optimized precisely for such calculations.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Und jetzt ahnt man vielleicht schon, warum leistungsfähige "
"Grafikkarten für das Training und die Anwendung von KI-Modellen so beliebt "
"sind: Das Rechnen mit Vektoren, Skalarprodukten (und später auch noch "
"Berechnungen mit Matrizen) sind genau die Anwendungsfälle, in denen "
"Grafikkarten einem normalen Prozessor deutlich überlegen sind, da sie genau "
"für solche Berechnungen gebaut und optimiert werden.</p>\n"
"            "

#: ../Perceptron.py:270
msgid ""
"\n"
"            <p>The mathematically simplified model now looks like this:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Das mathematisch vereinfachte Modell sieht nun so aus:</p>\n"
"            "

#: ../Perceptron.py:280
msgid ""
"\n"
"            <p>Let us now return to point 3 of the above-mentioned learning\n"
"            process and the question of the\n"
"            <span style=\"color:red\">reasonable direction</span> of the\n"
"            weighting adjustments. The answer to this question is as "
"follows:\n"
"            Find the difference &delta; between the target value t (the "
"value\n"
"            we expect given a certain input) and the output o (the value "
"the\n"
"            neuron actually output):<p>\n"
"            "
msgstr ""
"\n"
"            <p>Kommen wir nun zu Punkt 3 des oben erwähnten Lernprozesses "
"und der Frage nach der <span style=\"color:red\">sinnvollen Richtung</span> "
"der Anpassung zurück. Die Antwort auf diese Frage ist wie folgt: Ermittle "
"die Differenz &delta; zwischen dem Zielwert t (dem Wert, den wir bei einer "
"bestimmten Eingabe erwarten) und der Ausgabe o (dem Wert, den die "
"Nervenzelle tatsächlich ausgegeben hat):<p>\n"
"            "

#: ../Perceptron.py:290
msgid ""
"\n"
"            <p>If &delta; is positive, increase the weights, otherwise "
"decrease\n"
"            them.</p>\n"
"            "
msgstr ""
"\n"
"            <p>Wenn &delta; positiv ist, erhöhe die Gewichtungen, ansonsten "
"verringere sie.</p>\n"
"            "

#: ../Perceptron.py:294
msgid ""
"\n"
"            <p>This obviously leads immediately to the next question: Which "
"of\n"
"            the three weights should be adjusted and\n"
"            <span style=\"color:red\">to what extent</span>?</p>\n"
"            "
msgstr ""
"\n"
"            <p>Das führt offensichtlich sofort zur nächsten Frage: Welche "
"der drei Gewichtungen sollte <span style=\"color:red\">wie stark</span> "
"angepasst werden?</p>\n"
"            "

#: ../Perceptron.py:299
msgid ""
"\n"
"            <p>Three considerations are combined to answer this question:</"
"p>\n"
"            "
msgstr ""
"\n"
"            <p>Zur Lösung dieser Frage werden drei Überlegungen miteinander "
"kombiniert:</p>\n"
"            "

#: ../Perceptron.py:302
msgid ""
"\n"
"            <p>The greater the error that occurred, the more the weights "
"need\n"
"            to be corrected. The new value of each weight is therefore\n"
"            initially the product of its previous value and the size of the\n"
"            difference &delta; that occurred:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Je stärker der aufgetretene Fehler war, umso stärker müssen "
"die Gewichtungen korrigiert werden. Der neue Wert einer jeden Gewichtung ist "
"also zunächst einmal das Produkt aus dessen bisherigem Wert und der Größe "
"der aufgetretenen Differenz &delta;:</p>\n"
"            "

#: ../Perceptron.py:312
msgid ""
"\n"
"            <p>However, the difference may be so large that we overshoot "
"the\n"
"            target with the new weights. We therefore introduce another\n"
"            factor, the learning rate &alpha;:</p>\n"
"            "
msgstr ""
"\n"
"            <p>Die Differenz kann jedoch unter Umständen so groß sein, dass "
"wir mit den neuen Gewichtungen viel zu weit über das Ziel hinausschießen. "
"Daher führen wir einen weiteren Faktor, die Lernrate &alpha;, ein:</p>\n"
"            "

#: ../Perceptron.py:321
msgid ""
"\n"
"            <p>A further consideration is that inputs that have delivered "
"the\n"
"            strongest signal in the event of an error have also contributed "
"the\n"
"            most to the error. The consequence of this is that the strength "
"of\n"
"            the respective input should also be included in the correction:</"
"p>\n"
"            "
msgstr ""
"\n"
"            <p>Eine weitere Überlegung ist, dass Eingaben, die im Fehlerfall "
"das stärkste Signal geliefert haben, auch am meisten zum Fehler beigetragen "
"haben. Die Konsequenz daraus ist, die Stärke der jeweiligen Eingabe "
"ebenfalls in die Korrektur einzubeziehen:</p>\n"
"            "

#: ../Perceptron.py:331
msgid ""
"\n"
"            <p>And now we have all the ingredients for a first small "
"artificial\n"
"            neuron!</p>\n"
"            "
msgstr ""
"\n"
"            <p>Und damit haben wir nun alle Zutaten für eine erste kleine "
"künstliche Nervenzelle!</p>\n"
"            "

#: ../Perceptron.py:346
msgid ""
"\n"
"            <h1>Training</h1>\n"
"            In this area the artificial neuron can be trained:\n"
"            <ol>\n"
"                <li>\n"
"                    Select the checkboxes for the combinations you consider "
"a\n"
"                    nice day in the rightmost column.\n"
"                </li>\n"
"                <li>Press the start button to start the learning process.</"
"li>\n"
"                <li>\n"
"                    Press the same button to continue the learning process\n"
"                    step-by-step.\n"
"                </li>\n"
"                <li>\n"
"                    Press the \"Finalize Epoch\" button to continue "
"learning\n"
"                    until the current epoch is finished (all inputs have "
"been\n"
"                    tested once).\n"
"                </li>\n"
"                <li>\n"
"                    Press the \"Reset\" button to reset the learning "
"process.\n"
"                </li>\n"
"            </ol>\n"
"            "
msgstr ""
"\n"
"            <h1>Training</h1>\n"
"            In diesem Bereich kann die künstliche Nervenzelle trainiert "
"werden:\n"
"            <ol>\n"
"                <li>\n"
"                    Wählen Sie in der rechten Spalte die Checkboxen für die "
"Kombinationen, die Sie für schöne Tage halten.                 </li>\n"
"                <li>Drücken Sie den Startknopf, um den Lernprozess zu "
"starten.</li>\n"
"                <li>Drücken Sie den gleichen Knopf, um den Lernprozess "
"schrittweise fortzusetzen."
"                <li>\n"
"                    Drücken Sie den Knopf \"Epoche abschließen\", um so "
"lange zu lernen, bis die aktuelle Epoche abgeschlossen wurde (alle Eingaben "
"wurden einmal getestet).                </li>\n"
"                <li>\n"
"                    Drücken Sie den Knopf \"Zurücksetzen\", um den "
"Lernprozess zurückzusetzen.                </li>\n"
"            </ol>\n"
"            "

#: ../Perceptron.py:385
msgid "Weekend"
msgstr "Wochenende"

#: ../Perceptron.py:407
msgid "Visiting Parents"
msgstr "Eltern zu Besuch"

#: ../Perceptron.py:429
msgid "Nice Day?"
msgstr "Schöner Tag?"

#: ../Perceptron.py:447
msgid "Learning Rate α:"
msgstr "Lernrate α"

#: ../Perceptron.py:455
msgid "Finalize Epoch"
msgstr "Epoche abschließen"

#: ../Perceptron.py:459
msgid "Reset"
msgstr "Zurücksetzen"

#: ../Perceptron.py:472
msgid ""
"\n"
"            <h2>Task</h2>\n"
"            <p>In our simple example, there are 16 different variants, "
"which\n"
"            could be a nice day (4 checkboxes = 4 bits, 2<sup>4</sup>=16).\n"
"            However, a single artificial neuron can <em>NOT</em> "
"successfully\n"
"            learn two specific variants (the reason for this will follow). "
"Try\n"
"            to find out which two variants these are.</p>\n"
"            "
msgstr ""
"\n"
"            <h2>Aufgabe</h2>\n"
"            <p>In unserem einfachen Beispiel gibt es 16 verschiedene "
"Varianten, was ein schöner Tag sein könnte (4 Checkboxen = 4 Bits, 2<sup>4</"
"sup>=16). Eine einzelne künstliche Nervenzelle kann jedoch zwei spezielle "
"Varianten <em>NICHT</em> erfolgreich lernen (die Begründung dafür folgt "
"noch). Versuchen Sie herauszufinden, welche zwei Varianten das sind.</p>\n"
"            "

#: ../Perceptron.py:480
msgid ""
"\n"
"            <h2>Resource consumption in machine learning</h2>\n"
"            <p>When training the artificial neuron, you may have noticed "
"that\n"
"            this process can take very different lengths of time, depending "
"on\n"
"            the randomly selected starting values of the weights. In the "
"worst\n"
"            case, even in our simple example, the training can take several\n"
"            dozen weight adjustments before the artificial neuron produces "
"the\n"
"            desired output. This hopefully makes it clear why the resource\n"
"            consumption for training an entire neural network with not just\n"
"            three but several billion parameters takes so long and consumes "
"so\n"
"            many resources.</p>\n"
"            "
msgstr ""
"\n"
"            <h2>Ressourcenverbrauch beim Maschinellen Lernen</h2>\n"
"            <p>Beim Training der künstlichen Nervenzelle ist Ihnen "
"vielleicht aufgefallen, dass dieser Prozess, abhängig von den zufällig "
"gewählten Startwerten der Gewichtungen, sehr unterschiedlich lang dauern "
"kann. Im schlimmsten Fall kann das Training selbst in unserem einfachen "
"Beispiel mehrere Dutzend Gewichtsanpassungen benötigen, bis die künstliche "
"Nervenzelle die gewünschten Ausgaben produziert. Das verdeutlicht "
"hoffentlich, warum der Ressourcenverbrauch für das Training eines ganzen "
"neuronalen Netzwerks mit nicht nur drei sondern mit mehreren Milliarden "
"Parametern so lange braucht und so enorm viel Ressourcen verbraucht.</p>\n"
"            "

#: ../Perceptron.py:496
msgid ""
"\n"
"            <h1>Inference</h1>\n"
"            In this area the trained artificial neuron can be tested:\n"
"            <ol>\n"
"                <li>\n"
"                    Change the selection of the two input checkboxes on the\n"
"                    left hand side.\n"
"                </li>\n"
"                <li>Watch the result on the righthand side.</li>\n"
"            </ol>\n"
"            "
msgstr ""
"\n"
"            <h1>Inferenz</h1>\n"
"            In diesem Bereich kann die trainierte künstliche Nervenzelle "
"getestet werden:\n"
"            <ol>\n"
"                <li>\n"
"                    Ändern Sie die Auswahl der beiden Eingabe-Checkboxen auf "
"der linken Seite.                 </li>\n"
"                <li>Beobachten Sie das Ergebnis auf der rechten Seite.</li>\n"
"            </ol>\n"
"            "

#: ../Perceptron.py:553
msgid "Start (set random weights))"
msgstr "Start (zufällige Gewichtungen setzen)"

#: ../Perceptron.py:558
msgid "Continue (get random input)"
msgstr "Weiter (zufälligen Input holen)"

#: ../Perceptron.py:560
msgid "Continue (calculate result)"
msgstr "Weiter (Ausgabe berechnen)"

#: ../Perceptron.py:562
msgid "Continue (adopt weights)"
msgstr "Weiter (Gewichtungen anpassen)"

#: ../Perceptron.py:609 ../Perceptron.py:757
msgid "Epoch: "
msgstr "Epoche: "

#: ../temp.py:52
msgid ""
"\n"
"                <h1>Startup failed</h1>\n"
"                The startup of this notebook has failed. A known cause for "
"this\n"
"                error is starting the notebook in Firefox in private mode.\n"
"                Please try again in a new Firefox window in normal mode. "
"More\n"
"                background information about this problem can be found "
"here:\n"
"                <br>\n"
"                <a href=\"https://jupyterlite.readthedocs.io/en/latest/howto/"
"configure/advanced/service-worker.html\" target=\"_blank\">\n"
"                https://jupyterlite.readthedocs.io/en/latest/howto/configure/"
"advanced/service-worker.html</a>\n"
"                "
msgstr ""
"\n"
"                <h1>Start fehlgeschlagen</h1>\n"
"                Der Start dieses Notebooks ist fehlgeschlagen. Eine "
"bekannte                Ursache für diesen Fehler ist der Start des "
"Notebooks in                Firefox im privaten Modus. Bitte versuchen Sie "
"es noch einmal                in einem neuen Firefox-Fenster im normalen "
"Modus. Weitere                Hintergrundinformationen zu diesem Problem "
"sind hier zu                finden:                <br>\n"
"                <a href=\"https://jupyterlite.readthedocs.io/en/latest/howto/"
"configure/advanced/service-worker.html\" target=\"_blank\">\n"
"                https://jupyterlite.readthedocs.io/en/latest/howto/configure/"
"advanced/service-worker.html</a>\n"
"                "
